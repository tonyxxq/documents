## Random Forest（随机森林）

随机森林属于集成算法（Ensemble Learning）中的 bagging 算法，集成算法主要分为两种，bagging 和 boosting。

####bagging 和 boosting 算法：

**bagging 算法（套袋法）**： 从原始样本集中使用 Bootstrap 方法随机抽取 n 个训练样本，共进行 k 轮抽取，得到 k 个训练集。（k 个训练集之间相互独立，元素可以有重复），对于 k 个训练集，我们训练 k 个模型（这 k 个模型可以根据具体问题而定，比如决策树，knn 等）

对于分类问题：由投票表决产生分类结果；对于回归问题：由k个模型预测结果的均值作为最后预测结果。（所有模型的重要性相同）

> Boostrap（自助法）：在自身样本重采样的方法来估计真实分布的问题，当我们不知道样本分布的时候，bootstrap 方法最有用，比较适合小样本的样本集合。

**Boosting 算法（提升法）**：对于训练集中的每个样本建立权值 W<sub>i</sub>，表示对每个样本的关注度。当某个样本被误分类的概率很高时，需要加大对该样本的权值。

进行迭代的过程中，每一步迭代都是一个弱分类器。我们需要用某种策略将其组合，作为最终模型。（例如AdaBoost 给每个弱分类器一个权值，将其线性组合最为最终分类器。误差越小的弱分类器，权值越大）

**注意：bagging 算法没有关于样本的权重和函数的权重，并且样本的选择是 Bootstrap 方法而 Boosting 算法是对所有的样本数据** 

####随机森林算法：

> 要理解随机森林，重点是理解两个随机
>
> 1. 样本的抽取是通过 Bootstrap 算法从样本集有放回的抽取 n 个子样本集
> 2. 对于每个子样本集在建立决策树的时候，不是利用全部特征而是随机的选择特征

随机森林是一种重要的基于 Bagging 的集成学习方法，可以用来做分类、回归等问题

优点：

- 具有**极高的准确率**
- 随机性的引入，使得随机森林**不容易过拟合**
- 随机性的引入，使得随机森林有**很好的抗噪声能力**
- 能处理很高维度的数据，并且不用做特征选择
- 既能处理离散型数据，也能处理连续型数据，数据集无需规范化
- 训练速度快，可以得到变量重要性排序
- **容易实现并行化**（多个样本集可以同时进行训练，Adaboosting 只能按序列进行）

缺点：

- 当随机森林中的决策树个数很多时，训练时需要的空间和时间会较大
- 随机森林模型还有许多不好解释的地方，有点算个黑盒模型

过程：

1. 从原始训练集中使用 Bootstrap 方法随机有放回**随机**采样选出 m 个样本，共进行 n 次采样，生成 n 个训练集
2. 对于 n 个训练集，我们分别训练 n 个决策树模型
3. 对于单个决策树模型，假设训练样本特征的个数为 f, **随机**在 f 个样本中选取 p 个特征（p << f），那么每次分裂时根据信息增益/信息增益比/基尼指数选择最好的特征进行分裂
4. 每棵树都一直这样分裂下去，直到该节点的所有训练样例都属于同一类。**在决策树的分裂过程中不需要剪枝**
5. 将生成的多棵决策树组成随机森林。对于分类问题，按多棵树分类器投票决定最终分类结果；对于回归问题，由多棵树预测值的均值决定最终预测结果。



示例代码：

```python
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
import pandas as pd
import numpy as np

# 加载数据
iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['species'] = pd.Factor(iris.target, iris.target_names)
df.head()

# 训练集和测试集
df['is_train'] = np.random.uniform(0, 1, len(df)) <= .75
train, test = df[df['is_train']==True], df[df['is_train']==False]

# 建立随机森林
features = df.columns[:4]
clf = RandomForestClassifier(n_jobs=2)
y, _ = pd.factorize(train['species'])
clf.fit(train[features], y)

# 测试集预测
preds = iris.target_names[clf.predict(test[features])]
pd.crosstab(test['species'], preds, rownames=['actual'], colnames=['preds'])
```





参考：https://blog.csdn.net/qq547276542/article/details/78304454





