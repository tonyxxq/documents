### MADDPG(Multi-Agent Deep Deterministic Policy Gradient)

为什么使用 MADDPG：强化学习中很多场景涉及多个智能体的交互，比如多个机器人的控制，语言的交流，多玩家的游戏等等。不过传统的RL方法，比如Q-Learning或者policy gradient都不适用于多智能体环境。主要的问题是，在训练过程中，每个智能体的策略都在变化，因此从每个智能体的角度来看，环境变得十分不稳定(**其他智能体的行动带来环境变化, 而不仅仅是自己的行动使环境变化**)。对 DQN 来说，经验重放的方法变的不再适用(如果不知道其他智能体的状态，那么不同情况下自身的状态转移会不同），而对 PG 的方法来说，环境的不断变化导致了学习的方差进一步增大， 所以引入了 MADDPG。





